# Linear_Reasoning_Features Cheatsheet

## Key Project Directories and Files

- `dataset/`  
  Contains datasets used for experiments, including subsets like `ceval-exam/`, `gsm-symbolic_data/`, `gsm8k/`, `HumanEval/`, `mbpp/`, `mgsm/`, `mmlu-pro/`, and `PopQA/`.  
  - Example files:  
    - `dataset/mmlu-pro-600samples.json`  
    - `dataset/ceval-exam/subject_mapping.json`  
    - `dataset/gsm-symbolic_data/GSM_symbolic.jsonl`

- `reasoning_representation/`  
  Contains notebooks and scripts for storing hidden states and analyzing reasoning features.  
  - Important notebooks:  
    - `LiReFs_storing_hs.ipynb` — Stores hidden states of models on certain tasks.  
    - `Figures_Interp_Reason&Memory.ipynb` — Creates PCA and other figures for interpretation.

- `Intervention/`  
  Contains scripts for intervention experiments on reasoning features.  
  - Key script:  
    - `features_intervention.py` — Runs intervention experiments manipulating reasoning features.

- `models/`  
  Contains pre-trained models used in experiments, e.g., `Llama-3.2-1B/`.

- `outputs/`  
  Directory for experiment outputs and results.

## Default Dataset Configuration

- The dataset is provided as a zip file `dataset.zip` which should be unzipped before running experiments.
- The datasets include various reasoning and memorization benchmark subsets used in the paper's experiments.

## Running the Project

1. Unzip the dataset:  
   ```sh
   unzip dataset.zip
   ```

2. Store hidden states by running:  
   `reasoning_representation/LiReFs_storing_hs.ipynb`

3. Generate figures by running:  
   `reasoning_representation/Figures_Interp_Reason&Memory.ipynb`

   - This notebook visualizes the linear reasoning features (LiReFs) in the model's hidden states.
   - It uses PCA to show separation between reasoning and memory hidden states.
   - Computes a "reasoning direction" vector as the mean difference between reasoning and memory hidden states.
   - Analyzes cosine similarities between this direction and hidden states across layers.
   - Plots logistic regression decision boundaries and cosine similarity heatmaps.
   - Examines correlations between reasoning scores and projections on the reasoning direction.
   - These analyses identify key linear directions that separate reasoning from memory representations.

4. Run intervention experiments:  
   ```sh
   cd Intervention
   python features_intervention.py
   ```
   - (the candidate directions are generated by a sweep of all layers of a model)
   - This script uses the candidate directions derived from the hidden states (including the reasoning direction) to perform targeted feature interventions.
   - Interventions modify or ablate components aligned with these directions at different model layers.
   - The experiments evaluate the causal impact of these linear reasoning features on reasoning and memory performance.
   - The plots and analyses from the figures notebook provide the foundation and justification for these interventions.

## References

- Paper: [The Reasoning-Memorization Interplay in Language Models Is Mediated by a Single Direction](https://arxiv.org/abs/2503.23084)
